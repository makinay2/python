{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc8499d",
   "metadata": {},
   "source": [
    "# Python for Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f58da7",
   "metadata": {},
   "source": [
    "## Built-in Data Structures\n",
    "\n",
    "- Python arrays are called “list,” and it will expand automatically. \n",
    "\n",
    "- Associative arrays (or hash tables) are called “dict.” \n",
    "\n",
    "- “tuple” is a read-only list \n",
    "\n",
    "- “set” as a container for unique items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35af49",
   "metadata": {},
   "source": [
    "- we can make use of the dict to build a counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2690319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 1, 'o': 2, 'r': 1, 't': 1, 'e': 5, 'z': 1, ' ': 8, 'c': 1, 'v': 1, 'i': 3, 'u': 5, 'x': 1, 'w': 1, 'h': 1, 's': 1, 'k': 1, 'y': 1, 'a': 1, 'j': 1, 'g': 1, 'b': 1, 'l': 1, 'n': 1, 'd': 1, 'q': 1, 'f': 1, 'm': 1}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Portez ce vieux whisky au juge blond qui fume\"\n",
    "counter = {}\n",
    "for char in sentence:\n",
    "    if char not in counter:\n",
    "        counter[char] = 0\n",
    "    counter[char] += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7d876",
   "metadata": {},
   "source": [
    "- we can use + to concatenate lists. In the above, we use += to extend the list A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf52d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 'fizz', 4, 'buzz', 'fizz', 7, 8, 'fizz', 'buzz', 11, 'fizz', 13, 14, 'fizzbuzz']\n"
     ]
    }
   ],
   "source": [
    "A = [1, 2, \"fizz\", 4, \"buzz\", \"fizz\", 7]\n",
    "A += [8, \"fizz\", \"buzz\", 11, \"fizz\", 13, 14, \"fizzbuzz\"]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3ea56",
   "metadata": {},
   "source": [
    "- swap two variables in a very clean syntax using tiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac1e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is 42; b is foo\n",
      "After swap, a is foo; b is 42\n"
     ]
    }
   ],
   "source": [
    "a = 42\n",
    "b = \"foo\"\n",
    "print(\"a is %s; b is %s\" % (a,b))\n",
    "a, b = b, a # swap\n",
    "print(\"After swap, a is %s; b is %s\" % (a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fd8b4",
   "metadata": {},
   "source": [
    "-  Python strings support substitution on the fly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154334c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square root of 10 is 3.162\n"
     ]
    }
   ],
   "source": [
    "template = \"Square root of %d is %.3f\"\n",
    "n = 10\n",
    "answer = template % (n, n**0.5)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28234f66",
   "metadata": {},
   "source": [
    "### Special variables\n",
    "\n",
    "- One notable “special” variable that you may often see in Python code is _, just an underscore character. It is by convention to mean a variable that we do not care about. \n",
    "\n",
    "- we use it to hold a return value from a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb50642",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x  y  z\n",
      "0  1  2  3\n",
      "1  2  3  4\n",
      "2  3  4  5\n",
      "3  5  6  7\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "A = pd.DataFrame([[1,2,3],[2,3,4],[3,4,5],[5,6,7]], columns=[\"x\",\"y\",\"z\"])\n",
    "print(A)\n",
    "\n",
    "for _, row in A.iterrows():\n",
    "      print(row[\"z\"])\n",
    "        \n",
    "## A.iterrows() return the index of row and the value of row, don't care about index s we use _        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576e7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0615a34",
   "metadata": {},
   "source": [
    "## Built-in functions\n",
    "\n",
    "- List of python built-in functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05597670",
   "metadata": {},
   "source": [
    "abs()\n",
    "aiter()\n",
    "all()\n",
    "any()\n",
    "anext()\n",
    "ascii()\n",
    "bin()\n",
    "bool()\n",
    "breakpoint()\n",
    "bytearray()\n",
    "bytes()\n",
    "callable()\n",
    "chr()\n",
    "classmethod()\n",
    "compile()\n",
    "complex()\n",
    "delattr()\n",
    "dict()\n",
    "dir()\n",
    "divmod()\n",
    "enumerate()\n",
    "eval()\n",
    "exec()\n",
    "filter()\n",
    "float()\n",
    "format()\n",
    "frozenset()\n",
    "getattr()\n",
    "globals()\n",
    "hasattr()\n",
    "hash()\n",
    "help()\n",
    "hex()\n",
    "id()\n",
    "input()\n",
    "int()\n",
    "isinstance()\n",
    "issubclass()\n",
    "iter()\n",
    "len()\n",
    "list()\n",
    "locals()\n",
    "map()\n",
    "max()\n",
    "memoryview()\n",
    "min()\n",
    "next()\n",
    "object()\n",
    "oct()\n",
    "open()\n",
    "ord()\n",
    "pow()\n",
    "print()\n",
    "property()\n",
    "range()\n",
    "repr()\n",
    "reversed()\n",
    "round()\n",
    "set()\n",
    "setattr()\n",
    "slice()\n",
    "sorted()\n",
    "staticmethod()\n",
    "str()\n",
    "sum()\n",
    "super()\n",
    "tuple()\n",
    "type()\n",
    "vars()\n",
    "zip()\n",
    "__import__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc6fd7",
   "metadata": {},
   "source": [
    "- zip() allows you to combine multiple lists together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56002a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x', 3, 2.1)\n",
      "('y', 5, 2.5)\n",
      "('z', 7, 2.9)\n"
     ]
    }
   ],
   "source": [
    "a = [\"x\", \"y\", \"z\"]\n",
    "b = [3, 5, 7, 9]\n",
    "c = [2.1, 2.5, 2.9]\n",
    "for x in zip(a, b, c):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a94f5",
   "metadata": {},
   "source": [
    "- zip also help us  to “pivot” a list of list\n",
    "\n",
    "- The zip(*a) function in Python is used to unzip a list of iterables (such as lists or tuples). It takes multiple iterables as arguments and returns an iterator of tuples, where the i-th tuple contains the i-th element from each of the input iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c6e090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x', 'y', 'z')\n",
      "(3, 5, 7)\n",
      "(2.1, 2.5, 2.9)\n"
     ]
    }
   ],
   "source": [
    "a = [['x', 3, 2.1], ['y', 5, 2.5], ['z', 7, 2.9]]\n",
    "p,q,r = zip(*a)\n",
    "print(p)\n",
    "print(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6f074",
   "metadata": {},
   "source": [
    "- enumerate(): to number a list of items, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca5c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 0 is quick\n",
      "item 1 is brown\n",
      "item 2 is fox\n",
      "item 3 is jumps\n",
      "item 4 is over\n"
     ]
    }
   ],
   "source": [
    "a = [\"quick\", \"brown\", \"fox\", \"jumps\", \"over\"]\n",
    "for num, item in enumerate(a):\n",
    "    print(\"item %d is %s\" % (num, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f445332",
   "metadata": {},
   "source": [
    "- some functions that manipulate a list (or list-like data structures, which Python calls the “iterables”):\n",
    "\n",
    "    max(a): To find the maximum value in list a\n",
    "    \n",
    "    min(a): To find the minimum value in list a\n",
    "    \n",
    "    sum(a): To find the sum of values in list a\n",
    "    \n",
    "    reverse(a): To iterate from list a from back\n",
    "    \n",
    "    sorted(a): To return a copy of list a with elements in sorted order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173fb050",
   "metadata": {},
   "source": [
    "## Python Debugging Tools \n",
    "\n",
    "- The built-in debugger is pdb\n",
    "\n",
    "- debugger is to provide you with a slow-motion button to control the flow of a program. \n",
    "\n",
    "- It also allows you to freeze the program at a certain time and examine the state.\n",
    "\n",
    "- The simplest operation under a debugger is to step through the code. That is to run one line of code at a time and wait for your acknowledgment before proceeding to the next. The reason we want to run the program in a stop-and-go fashion is to allow us to check the logic and value or verify the algorithm.\n",
    "\n",
    "- For large code, debuggers also provide a breakpoint feature that will kick in when a specific line of code is reached. From that point onward, we can step through it line by line.\n",
    "\n",
    "- to run a programm with the Python debugger, we enter the following in the command line:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6ce07",
   "metadata": {},
   "source": [
    "- At the prompt, you can type in the debugger commands. \n",
    "\n",
    "EOF-    c-          d-        h-         list-      q-        rv-       undisplay-\n",
    "a-      cl-         debug-    help-      ll-        quit-     s-        unt-\n",
    "alias-  clear-      disable-  ignore-    longlist-  r-        source-   until-\n",
    "args-   commands-   display-  interact-  n-         restart-  step-     up-\n",
    "b-      condition-  down-     j-         next-      return-   tbreak-   w-\n",
    "break-  cont-       enable-   jump-      p-         retval-   u-        whatis-\n",
    "bt-     continue-   exit-     l-         pp-        run-      unalias-  where-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084aa4c5",
   "metadata": {},
   "source": [
    "- h: for hel\n",
    "\n",
    "- n: to run line by line\n",
    "\n",
    "- s: step into the f() function\n",
    "\n",
    "- until: run to let the debugger run the program until that line is reahced (until 11)\n",
    "\n",
    "- b: (breakpoint) to stop at a particular line whenever it is being run (b 40)\n",
    "\n",
    "- b: to place a breakpoint with a condition so that it will stop only if the condition is met. ( b 40, r1 > 0.5)\n",
    "\n",
    "- c: to continue until a trigger is met\n",
    "\n",
    "- bt: to show the traceback to check how we reached that point(maybe after a trigger reached)\n",
    "\n",
    "- p: to print the variables (or an expression) to check what value they are holding (p r1, r2)\n",
    "\n",
    "- l: to list the code around the current statement \n",
    "\n",
    "- manipulate variables while we are debugging.(p r1, r2) --> (r1 = 0.2)\n",
    "\n",
    "- up: moves our focus to one level up on the call stack (after bt showed call stack)\n",
    "\n",
    "-  q: to quit or hit Ctrl-D if your terminal supports it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m pdb pso.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56cbef",
   "metadata": {},
   "source": [
    " - pdb from Python is suitable only for programs running from scratch\n",
    " \n",
    " - Python extension from GDB help with a program already running but is stuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775abf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final & will make it run in the background \n",
    "python simpleqt.py &\n",
    "\n",
    "##  check for its process\n",
    "ps a | grep python\n",
    "\n",
    "## run gdp on running file--> 3997 the result that programm stuck \n",
    "gdb python 3997"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a194076",
   "metadata": {},
   "source": [
    "- The commands supported under GDB are py-list, py-bt, py-up, py-down, and py-print. They are comparable to the same commands in pdb without the py- prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be8fdf",
   "metadata": {},
   "source": [
    "## Profiling Python Code\n",
    "\n",
    "- Profiling is a technique to figure out how time is spent in a program. \n",
    "\n",
    "- helps to find the “hot spot” of a program and think about ways of improvement\n",
    "\n",
    "- example, to concatenate many short strings, we can use the join() function from strings or the + operator. which one is more efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e09e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m timeit 'longstr=\"\"' 'for x in range(1000): longstr += str(x)'\n",
    "python -m timeit '\"\".join([str(x) for x in range(1000)])'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70f0b3",
   "metadata": {},
   "source": [
    "- The above commands are to load the timeit module and pass on a single line of code for measurement. In the first case, we have two lines of statements, and they are passed on to the timeit module as two separate arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a270dbb",
   "metadata": {},
   "source": [
    "- -s option allows us to provide the “setup” code, which is executed before the profiling and not timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d91871",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m timeit '[x**0.5 for x in range(1000)]'\n",
    "python -m timeit -s 'from math import sqrt' '[sqrt(x) for x in range(1000)]'\n",
    "python -m timeit -s 'from numpy import sqrt' '[sqrt(x) for x in range(1000)]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14133881",
   "metadata": {},
   "source": [
    "- you can also run timeit in Python code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "measurements = timeit.repeat('[x**0.5 for x in range(1000)]', number=10000)\n",
    "print(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81d438",
   "metadata": {},
   "source": [
    "### The Profile Module\n",
    "\n",
    "- A program running slow can generally be due to two reasons: A part is running slow, or a part is running too many times, adding up and taking too much time. We call these “performance hogs” the hot spot.\n",
    "\n",
    "- run the profiler for a module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m cProfile hillclimb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8647c",
   "metadata": {},
   "source": [
    "- to see which function is called the most number of times, we can sort by ncalls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4375382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m cProfile -s ncalls hillclimb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d31fb",
   "metadata": {},
   "source": [
    "- The other sort options are as follows:\n",
    "- calls: Call count\n",
    "- cumulative: Cumulative time\n",
    "- cumtime: Cumulative time\n",
    "- file: File name\n",
    "- filename:\tFile name\n",
    "- module: File name\n",
    "- ncalls: Call count\n",
    "- pcalls: Primitive call count\n",
    "- line:\tLine number\n",
    "- name:\tFunction name\n",
    "- nfl: Name/file/line\n",
    "- stdname: Standard name\n",
    "- time: Internal time\n",
    "- tottime: Internal time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9783043",
   "metadata": {},
   "source": [
    "- save the profiler’s statistics for further processing as follows:\n",
    "\n",
    "-  it will run the program. But this will not print the statistics to the screen but save them into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m cProfile -o hillclimb.stats hillclimb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d94ad",
   "metadata": {},
   "source": [
    " - Afterward, we can use the pstats module like the following to open up the statistics file and provide us a prompt to manipulate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m pstats hillclimb.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31be53",
   "metadata": {},
   "source": [
    "- Using Profiler Inside Code: to profile a specific part of programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile as profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639c726",
   "metadata": {},
   "source": [
    "# Static Analyzers in Python\n",
    "\n",
    "- Static analyzers are tools that help you check your code without really running your code.\n",
    "\n",
    "- The most basic form of static analyzers is the syntax highlighters\n",
    "\n",
    "- Three useful libraries are: \n",
    "   \n",
    "    - Pylint\n",
    "    - Flake8\n",
    "    - mypy\n",
    "\n",
    "### Pylint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pylint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bd25e",
   "metadata": {},
   "source": [
    "- Pylint can check one script or the entire directory.\n",
    "\n",
    "- ask Pylint to tell us how good our code is before even running it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e495d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylint lenet5-notworking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb559a3",
   "metadata": {},
   "source": [
    "- If you provide the root directory of a module to Pylint, all components of the module will be checked by Pylint. In that case, you will see the path of different files at the beginning of each line.\n",
    "\n",
    "- Pylint may give false positives.--> error when it not an error\n",
    "\n",
    "- Pylint is to help us make our code align with the PEP8 coding style. \n",
    "\n",
    "- Pylint help us identify potential issues.\n",
    "\n",
    "- you know what Pylint should stop complaining about, you can request to ignore those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d36d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylint -d E0611 lenet5-notworking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc4228",
   "metadata": {},
   "source": [
    "- all errors of code E0611 will be ignored by Pylint.\n",
    "\n",
    "- You can disable multiple codes by a comma-separated list, e.g.,"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec303bfa",
   "metadata": {},
   "source": [
    "pylint -d E0611,C0301 lenet5-notworking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82628ce4",
   "metadata": {},
   "source": [
    "- to disable some issues on only a specific line or a specific part of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af56de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist  # pylint: disable=no-name-in-module\n",
    "from tensorflow.keras.models import Sequential # pylint: disable=E0611\n",
    "from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e8944",
   "metadata": {},
   "source": [
    "- The magic keyword pylint: will introduce Pylint-specific instructions. The code E0611 and the name no-name-in-module are the same. In the example above, Pylint will complain about the last two import statements but not the first two because of those special comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888df16",
   "metadata": {},
   "source": [
    "## Flake8\n",
    "\n",
    "- The tool Flake8 is indeed a wrapper over PyFlakes, McCabe, and pycodestyle. When you install flake8 with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da834935",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ce324",
   "metadata": {},
   "source": [
    "- Similar to Pylint, we can pass in a script or a directory for analysis.\n",
    "\n",
    "- But the focus of Flake8 is inclined toward coding style.\n",
    "\n",
    "- The error codes beginning with letter E are from pycodestyle, and those beginning with letter F are from PyFlakes.\n",
    "\n",
    "- It complains about coding style issues such as the use of (5,5) for not having a space after the comma. \n",
    "\n",
    "- Also see it can identify the use of variables before assignment.\n",
    "\n",
    "- Similar to Pylint, we can also ask Flake8 to ignore some complaints and those lines will not be printed in the output. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40443198",
   "metadata": {},
   "outputs": [],
   "source": [
    "flake8 --ignore E501,E231 lenet5-notworking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d2665",
   "metadata": {},
   "source": [
    "- We can also use magic comments to disable some complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # noqa: F401\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968463be",
   "metadata": {},
   "source": [
    "- Flake8 will look for the comment # noqa: to skip some complaints on those particular lines.\n",
    "\n",
    "## Mypy\n",
    "\n",
    "- Python is not a typed language so, unlike C or Java, you do not need to declare the types of some functions or variables before use.\n",
    "\n",
    "- But lately, Python has introduced type hint notation, so we can specify what type a function or variable intended to be without enforcing its compliance like a typed language.\n",
    "\n",
    "- One of the biggest benefits of using type hints in Python is to provide additional information for static analyzers to check. Mypy is the tool that can understand type hints.\n",
    "\n",
    "- Even without type hints, Mypy can still provide complaints similar to Pylint and Flake8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91170ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypy lenet5-notworking.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143de8cc",
   "metadata": {},
   "source": [
    "- It expects all libraries we used to come with a stub so the type checking can be done. This is because type hints are optional. \n",
    "\n",
    "\n",
    "- Some of the libraries have typing stubs available that enables mypy to check them better.\n",
    "\n",
    "- In conclusion, the three tools we introduced above can be complementary to each other. You may consider to run all of them to look for any possible bugs in your code or improve the coding style. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ae35c",
   "metadata": {},
   "source": [
    "# Running a Python Script in Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d505301",
   "metadata": {},
   "source": [
    "- Running a Python script in command line is powerful because you can pass in additional parameters to the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "n = int(sys.argv[1])\n",
    "print(n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03278dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python commandline.py 15\n",
    "16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702607d0",
   "metadata": {},
   "source": [
    "- The list sys.argv contains the name of our script and all the arguments (all strings), which in the above case, is [\"commandline.py\", \"15\"].\n",
    "\n",
    "- Python provided the library argparse to help with multiple and more complicated set of arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -a -v --exclude=\"*.pyc\" -B 1024 --ignore-existing 192.168.0.3:/tmp/ ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fef73",
   "metadata": {},
   "source": [
    "- The optional arguments are introduced by “-” or “--“, where a single hyphen will carry a single character “short option” (such as -a, -B, and -v above), and two hyphens are for multiple characters “long options” (such as --exclude and --ignore-existing above). \n",
    "\n",
    "- The optional arguments may have additional parameters, such as in -B 1024 or --exclude=\"*.pyc\"; the 1024 and \"*.pyc\" are parameters to -B and --exclude, respectively. \n",
    "\n",
    "- Additionally, we may also have compulsory arguments, which we just put into the command line. The part 192.168.0.3:/tmp/ and ./ above are examples. The order of compulsory arguments is important. For example, the rsync command above will copy files from 192.168.0.3:/tmp/ to ./ instead of the other way round.\n",
    "\n",
    "- The following replicates the above example in Python using argparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Just an example\",\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"-a\", \"--archive\", action=\"store_true\", help=\"archive mode\")\n",
    "parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"increase verbosity\")\n",
    "parser.add_argument(\"-B\", \"--block-size\", help=\"checksum blocksize\")\n",
    "parser.add_argument(\"--ignore-existing\", action=\"store_true\", help=\"skip files that exist\")\n",
    "parser.add_argument(\"--exclude\", help=\"files to exclude\")\n",
    "parser.add_argument(\"src\", help=\"Source location\")\n",
    "parser.add_argument(\"dest\", help=\"Destination location\")\n",
    "args = parser.parse_args()\n",
    "config = vars(args)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52d0fb",
   "metadata": {},
   "source": [
    "- If you run the above script, you will see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7155d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python argparse_example.py\n",
    "usage: argparse_example.py [-h] [-a] [-v] [-B BLOCK_SIZE] [--ignore-existing] [--exclude EXCLUDE] src dest\n",
    "argparse_example.py: error: the following arguments are required: src, dest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ffa0b9",
   "metadata": {},
   "source": [
    "- This means you didn’t provide the compulsory arguments for src and dest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019ed1d",
   "metadata": {},
   "source": [
    "## Working on the Command Line\n",
    "\n",
    "- Empowering your Python script with command line arguments can bring it to a new level of reusability.\n",
    "\n",
    "- let’s look at a simple example of fitting an ARIMA model to a GDP time series. World Bank collects historical GDP data from many countries. We can make use of the pandas_datareader package to read the data. \n",
    "\n",
    "- we use is NY.GDP.MKTP.CN; we can get the data of a country in the form of a pandas DataFrame \n",
    "\n",
    "- Fitting an ARIMA model and using the model for predictions is not difficult. In the following, we fit it using the first 40 data points and forecast for the next 3. Then compare the forecast with the actual in terms of relative error\n",
    "\n",
    "- use argparse so that we can change some parameters from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from pandas_datareader.wb import WorldBankReader\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Parse command line arguments\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"-c\", \"--country\", default=\"SE\", help=\"Two-letter country code\")\n",
    "parser.add_argument(\"-l\", \"--length\", default=40, type=int, help=\"Length of time series to fit the ARIMA model\")\n",
    "parser.add_argument(\"-s\", \"--start\", default=0, type=int, help=\"Starting offset to fit the ARIMA model\")\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "# Set up parameters\n",
    "series = \"NY.GDP.MKTP.CN\"\n",
    "country = args[\"country\"]\n",
    "length = args[\"length\"]\n",
    "start = args[\"start\"]\n",
    "steps = 3\n",
    "order = (1,1,1)\n",
    "\n",
    "# Read the GDP data from WorldBank database\n",
    "gdp = WorldBankReader(series, country, start=1960, end=2020).read()\n",
    "# Drop country name from index\n",
    "gdp = gdp.droplevel(level=0, axis=0)\n",
    "# Sort data in choronological order and set data point at year-end\n",
    "gdp.index = pd.to_datetime(gdp.index)\n",
    "gdp = gdp.sort_index().resample(\"y\").last()\n",
    "# Convert pandas dataframe into pandas series\n",
    "gdp = gdp[series]\n",
    "# Fit arima model\n",
    "result = sm.tsa.ARIMA(endog=gdp[start:start+length], order=order).fit()\n",
    "# Forecast, and calculate the relative error\n",
    "forecast = result.forecast(steps=steps)\n",
    "df = pd.DataFrame({\"Actual\":gdp, \"Forecast\":forecast}).dropna()\n",
    "df[\"Rel Error\"] = (df[\"Forecast\"] - df[\"Actual\"]) / df[\"Actual\"]\n",
    "# Print result\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07102c6d",
   "metadata": {},
   "source": [
    "- If we run the code above in a command line, we can see it can now accept arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0122be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python gdp_arima.py --help\n",
    "usage: gdp_arima.py [-h] [-c COUNTRY] [-l LENGTH] [-s START]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -c COUNTRY, --country COUNTRY\n",
    "                        Two-letter country code (default: SE)\n",
    "  -l LENGTH, --length LENGTH\n",
    "                        Length of time series to fit the ARIMA model (default: 40)\n",
    "  -s START, --start START\n",
    "                        Starting offset to fit the ARIMA model (default: 0)\n",
    "python gdp_arima.py\n",
    "                   Actual      Forecast  Rel Error\n",
    "2000-12-31  2408151000000  2.367152e+12  -0.017025\n",
    "2001-12-31  2503731000000  2.449716e+12  -0.021574\n",
    "2002-12-31  2598336000000  2.516118e+12  -0.031643\n",
    "\n",
    "python gdp_arima.py -c NO\n",
    "                   Actual      Forecast  Rel Error\n",
    "2000-12-31  1507283000000  1.337229e+12  -0.112821\n",
    "2001-12-31  1564306000000  1.408769e+12  -0.099429\n",
    "2002-12-31  1561026000000  1.480307e+12  -0.051709"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe142e93",
   "metadata": {},
   "source": [
    " - In the last command above, we pass in -c NO to apply the same model to the GDP data of Norway (NO) instead of Sweden (SE). Hence, without the risk of messing up the code, we reused our code for a different dataset.\n",
    " \n",
    "- The power of introducing a command line argument is that we can easily test our code with varying parameters. \n",
    "\n",
    "- For example, we want to see if the ARIMA(1,1,1) model is a good model for predicting GDP, and we want to verify with a different time window of the Nordic countries:\n",
    "\n",
    "    - Denmark (DK)\n",
    "    - Finland (FI)\n",
    "    - Iceland (IS)\n",
    "    - Norway (NO)\n",
    "    - Sweden (SE)\n",
    "\n",
    "- We want to check for the window of 40 years but with different starting points (since 1960, 1965, 1970, 1975). Depending on the OS, you can build a for loop in Linux and mac using the bash shell syntax.\n",
    "\n",
    "- as the shell syntax permits, we can put everything in one line:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b755c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in DK FI IS NO SE; do for S in 0 5 10 15; do python gdp_arima.py -c $C -s $S ; done ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb58d0",
   "metadata": {},
   "source": [
    "- If you’re using Windows, you can use the following syntax in command prompt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for %C in (DK FI IS NO SE) do for %S in (0 5 10 15) do python gdp_arima.py -c $C -s $S\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d4ce7",
   "metadata": {},
   "source": [
    "- or the following in PowerShell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreach ($C in \"DK\",\"FI\",\"IS\",\"NO\",\"SE\") { foreach ($S in 0,5,10,15) { python gdp_arima.py -c $C -s $S } }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714adf2a",
   "metadata": {},
   "source": [
    "## Alternative to command line arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a789457",
   "metadata": {},
   "source": [
    " At least, there are several other ways too:\n",
    "\n",
    "    using environment variables\n",
    "    using config files\n",
    "\n",
    "Environment variables are features from your OS to keep a small amount of data in memory. We can read environment variables in Python using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04654c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ[\"MYVALUE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5850f0b9",
   "metadata": {},
   "source": [
    "- the above two-line script will work with the shell as follows in windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\MLM> set MYVALUE=hello\n",
    "\n",
    "C:\\MLM> python show_env.py\n",
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a08ea",
   "metadata": {},
   "source": [
    "- In case we have a lot of options to set, it is better to save the options to a file rather than overwhelming the command line. \n",
    "\n",
    "- Depending on the format we chose, we can use the configparser or json module from Python to read the Windows INI format or JSON format, respectively. \n",
    "\n",
    "- We may also use the third-party library PyYAML to read the YAML format.\n",
    "\n",
    "- For the above example running the ARIMA model on GDP data, we can modify the code to use a YAML config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ad839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from pandas_datareader.wb import WorldBankReader\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Load config from YAML file\n",
    "with open(\"config.yaml\", \"r\") as fp:\n",
    "    args = yaml.safe_load(fp)\n",
    "\n",
    "# Set up parameters\n",
    "series = \"NY.GDP.MKTP.CN\"\n",
    "country = args[\"country\"]\n",
    "length = args[\"length\"]\n",
    "start = args[\"start\"]\n",
    "steps = 3\n",
    "order = (1,1,1)\n",
    "\n",
    "# Read the GDP data from WorldBank database\n",
    "gdp = WorldBankReader(series, country, start=1960, end=2020).read()\n",
    "# Drop country name from index\n",
    "gdp = gdp.droplevel(level=0, axis=0)\n",
    "# Sort data in choronological order and set data point at year-end\n",
    "gdp.index = pd.to_datetime(gdp.index)\n",
    "gdp = gdp.sort_index().resample(\"y\").last()\n",
    "# Convert pandas dataframe into pandas series\n",
    "gdp = gdp[series]\n",
    "# Fit arima model\n",
    "result = sm.tsa.ARIMA(endog=gdp[start:start+length], order=order).fit()\n",
    "# Forecast, and calculate the relative error\n",
    "forecast = result.forecast(steps=steps)\n",
    "df = pd.DataFrame({\"Actual\":gdp, \"Forecast\":forecast}).dropna()\n",
    "df[\"Rel Error\"] = (df[\"Forecast\"] - df[\"Actual\"]) / df[\"Actual\"]\n",
    "# Print result\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e2a0c7",
   "metadata": {},
   "source": [
    "- The YAML config file is named as config.yaml, and its content is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a394daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "country: SE\n",
    "length: 40\n",
    "start: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7dc86",
   "metadata": {},
   "source": [
    "- The JSON counterpart is very similar, where we use the load() function from the json module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dcd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from pandas_datareader.wb import WorldBankReader\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Load config from JSON file\n",
    "with open(\"config.json\", \"r\") as fp:\n",
    "    args = json.load(fp)\n",
    "\n",
    "# Set up parameters\n",
    "series = \"NY.GDP.MKTP.CN\"\n",
    "country = args[\"country\"]\n",
    "length = args[\"length\"]\n",
    "start = args[\"start\"]\n",
    "steps = 3\n",
    "order = (1,1,1)\n",
    "\n",
    "# Read the GDP data from WorldBank database\n",
    "gdp = WorldBankReader(series, country, start=1960, end=2020).read()\n",
    "# Drop country name from index\n",
    "gdp = gdp.droplevel(level=0, axis=0)\n",
    "# Sort data in choronological order and set data point at year-end\n",
    "gdp.index = pd.to_datetime(gdp.index)\n",
    "gdp = gdp.sort_index().resample(\"y\").last()\n",
    "# Convert pandas dataframe into pandas series\n",
    "gdp = gdp[series]\n",
    "# Fit arima model\n",
    "result = sm.tsa.ARIMA(endog=gdp[start:start+length], order=order).fit()\n",
    "# Forecast, and calculate the relative error\n",
    "forecast = result.forecast(steps=steps)\n",
    "df = pd.DataFrame({\"Actual\":gdp, \"Forecast\":forecast}).dropna()\n",
    "df[\"Rel Error\"] = (df[\"Forecast\"] - df[\"Actual\"]) / df[\"Actual\"]\n",
    "# Print result\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10161fb1",
   "metadata": {},
   "source": [
    "- And the JSON config file, config.json, would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a754fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"country\": \"SE\",\n",
    "    \"length\": 40,\n",
    "    \"start\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac9d95",
   "metadata": {},
   "source": [
    "## What is the decorator pattern, and why is it useful?\n",
    "\n",
    "- The decorator pattern is a software design pattern that allows us to dynamically add functionality to classes without creating subclasses and affecting the behavior of other objects of the same class.\n",
    "\n",
    "- By using the decorator pattern, we can easily generate different permutations of functionality that we might want without creating an exponentially increasing number of subclasses, making our code increasingly complex and bloated.\n",
    "\n",
    "- Decorators are usually implemented as sub-interfaces of the main interface that we want to implement and store an object of the main interface’s type.\n",
    "\n",
    "- It will then modify the methods to which it wants to add certain functionality by overriding the methods in the original interface and calling on methods from the stored object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f4940",
   "metadata": {},
   "source": [
    "### Function Decorators in Python\n",
    "\n",
    "- A function decorator is an incredibly useful feature in Python. It is built upon the idea that functions and classes are first-class objects in Python.\n",
    "\n",
    "-  Since a Python function is an object and we can pass a function as an argument to another function, this task can be done as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7619639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "def repeat(fn):\n",
    "    fn()\n",
    "    fn()\n",
    "\n",
    "def hello_world():\n",
    "    print(\"Hello world!\")\n",
    "\n",
    "repeat(hello_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d8955",
   "metadata": {},
   "source": [
    "- since a Python function is an object, we can make a function to return another function, which is to execute yet another function twice. This is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0240c274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "def repeat_decorator(fn):\n",
    "    def decorated_fn():\n",
    "        fn()\n",
    "        fn()\n",
    "    # returns a function\n",
    "    return decorated_fn\n",
    "\n",
    "def hello_world():\n",
    "    print (\"Hello world!\")\n",
    "\n",
    "hello_world_twice = repeat_decorator(hello_world)\n",
    "\n",
    "# call the function\n",
    "hello_world_twice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4837e52",
   "metadata": {},
   "source": [
    "- In the above, we passed the hello_world function as an argument to the repeat_decorator() function, and it returns the decorated_fn function, which is assigned to hello_world_twice. Afterward, we can invoke hello_world_twice() since it is now a function.\n",
    "\n",
    "- The idea of decorator pattern applies here. But we do not need to define the interface and subclasses explicitly. In fact, hello_world is a name defined as a function in the above example. There is nothing preventing us from redefining this name to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d11c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "# function decorator that calls the function twice\n",
    "def repeat_decorator(fn):\n",
    "    def decorated_fn():\n",
    "        fn()\n",
    "        fn()\n",
    "    # returns a function\n",
    "    return decorated_fn\n",
    "\n",
    "# using the decorator on hello_world function\n",
    "@repeat_decorator\n",
    "def hello_world():\n",
    "    print (\"Hello world!\")\n",
    "\n",
    "# call the function\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af78ed9",
   "metadata": {},
   "source": [
    "- In the above code, @repeat_decorator before a function definition means to pass the function into repeat_decorator() and reassign its name to the output. That is, to mean hello_world = repeat_decorator(hello_world). The @ line is the decorator syntax in Python.\n",
    "\n",
    "- We can also implement decorators that take in arguments, but this would be a bit more complicated as we need to have one more layer of nesting. If we extend our example above to define the number of times to repeat the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6018a676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Hello world!\n",
      "Hello world!\n",
      "Hello world!\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "def repeat_decorator(num_repeats = 2):\n",
    "    # repeat_decorator should return a function that's a decorator\n",
    "    def inner_decorator(fn):\n",
    "        def decorated_fn():\n",
    "            for i in range(num_repeats):\n",
    "                fn()\n",
    "        # return the new function\n",
    "        return decorated_fn\n",
    "    # return the decorator that actually takes the function in as the input\n",
    "    return inner_decorator\n",
    "\n",
    "# use the decorator with num_repeats argument set as 5 to repeat the function call 5 times\n",
    "@repeat_decorator(5)\n",
    "def hello_world():\n",
    "    print(\"Hello world!\")\n",
    "\n",
    "# call the function\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ac4fa",
   "metadata": {},
   "source": [
    "- The repeat_decorator() takes in an argument and returns a function which is the actual decorator for the hello_world function (i.e., invoking repeat_decorator(5) returns inner_decorator with the local variable num_repeats = 5 set).\n",
    "\n",
    "## The Use Cases of Decorators\n",
    "\n",
    "- One of the most common use cases is to convert data implicitly. For example, we may define a function that assumes all operations are based on numpy arrays and then make a decorator to ensure that happens by modifying the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function decorator to ensure numpy input\n",
    "def ensure_numpy(fn):\n",
    "    def decorated_function(data):\n",
    "        # converts input to numpy array\n",
    "        array = np.asarray(data)\n",
    "        # calls fn on input numpy array\n",
    "        return fn(array)\n",
    "    return decorated_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb30d6",
   "metadata": {},
   "source": [
    "- We can further add to our decorator by modifying the output of the function, such as rounding off floating point values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef319c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function decorator to ensure numpy input\n",
    "# and round off output to 4 decimal places\n",
    "def ensure_numpy(fn):\n",
    "    def decorated_function(data):\n",
    "        array = np.asarray(data)\n",
    "        output = fn(array)\n",
    "        return np.around(output, 4)\n",
    "    return decorated_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef732ee",
   "metadata": {},
   "source": [
    "- Let’s consider the example of finding the sum of an array. A numpy array has sum() built-in, as does pandas DataFrame. \n",
    "\n",
    "- But the latter is to sum over columns rather than sum over all elements. \n",
    "\n",
    "- Hence a numpy array will sum to one floating point value while a DataFrame will sum to a vector of values. \n",
    "\n",
    "- But with the above decorator, we can write a function that gives you consistent output in both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b676aec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.10826376 -1.8346967  -0.8656575 ]\n",
      " [ 0.83011178 -0.4462485   1.62806834]\n",
      " [ 0.57775645 -1.0687193  -0.75038706]\n",
      " [-0.20930878 -0.73197545 -0.39379396]\n",
      " [-0.29453276 -1.185483   -0.75592191]\n",
      " [-1.12707315  0.2844536   0.38370484]\n",
      " [-0.28469777  0.5582686  -2.05787598]\n",
      " [ 0.76308829 -0.36139811 -1.09883896]\n",
      " [ 0.47075571  0.53695196 -0.39533697]\n",
      " [-0.90400514  0.09515254  1.00264799]]\n",
      "          A         B         C\n",
      "0  1.108264 -1.834697 -0.865658\n",
      "1  0.830112 -0.446249  1.628068\n",
      "2  0.577756 -1.068719 -0.750387\n",
      "3 -0.209309 -0.731975 -0.393794\n",
      "4 -0.294533 -1.185483 -0.755922\n",
      "5 -1.127073  0.284454  0.383705\n",
      "6 -0.284698  0.558269 -2.057876\n",
      "7  0.763088 -0.361398 -1.098839\n",
      "8  0.470756  0.536952 -0.395337\n",
      "9 -0.904005  0.095153  1.002648\n",
      "x.sum(): -6.526727148650348\n",
      "\n",
      "y.sum(): A    0.930358\n",
      "B   -4.153694\n",
      "C   -3.303391\n",
      "dtype: float64\n",
      "\n",
      "numpysum(x): -6.5267\n",
      "numpysum(y): -6.5267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# function decorator to ensure numpy input\n",
    "# and round off output to 4 decimal places\n",
    "def ensure_numpy(fn):\n",
    "    def decorated_function(data):\n",
    "        array = np.asarray(data)\n",
    "        output = fn(array)\n",
    "        return np.around(output, 4)\n",
    "    return decorated_function\n",
    "\n",
    "@ensure_numpy\n",
    "def numpysum(array):\n",
    "    return array.sum()\n",
    "\n",
    "x = np.random.randn(10,3)\n",
    "print(x)\n",
    "y = pd.DataFrame(x, columns=[\"A\", \"B\", \"C\"])\n",
    "print(y)\n",
    "\n",
    "# output of numpy .sum() function\n",
    "print(\"x.sum():\", x.sum())\n",
    "print()\n",
    "\n",
    "# output of pandas .sum() funuction\n",
    "print(\"y.sum():\", y.sum())\n",
    "print()\n",
    "\n",
    "# calling decorated numpysum function\n",
    "print(\"numpysum(x):\", numpysum(x))\n",
    "print(\"numpysum(y):\", numpysum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681af66",
   "metadata": {},
   "source": [
    "- In the above code, @ensure_numpy before a function definition means to pass the function into ensure_numpy() and reassign its name to the output. That is, to mean numpysum = ensure_numpy(numpysum)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e0846",
   "metadata": {},
   "source": [
    "## Techniques to Write Better Python Code\n",
    "\n",
    "\n",
    "- Sanitation and assertive programming\n",
    "- Guard rails and offensive programming\n",
    "- Good practices to avoid bugs\n",
    "\n",
    "### Sanitation and Assertive \n",
    "\n",
    "- As Python is a duck-typing language, it is easy to see a function accepting numbers to be called with strings. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe04abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onetwo'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "c = add(\"one\", \"two\")\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fdade",
   "metadata": {},
   "source": [
    "- One common thing a fairly long code would do is to sanitize the input. For example, we may rewrite our function above as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc63b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n",
    "        raise ValueError(\"Input must be numbers\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1af6df",
   "metadata": {},
   "source": [
    "- Or, better, convert the input into a floating point whenever it is possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72480a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    try:\n",
    "        a = float(a)\n",
    "        b = float(b)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Input must be numbers\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251fe78",
   "metadata": {},
   "source": [
    "- The key here is to do some “sanitization” at the beginning of a function, so subsequently, we can assume the input is in a certain format. \n",
    "\n",
    "- Another reason to sanitize the input is for canonicalization. This means we should make the input in a standardized format.\n",
    "\n",
    "-  For example, a URL should start with “http://,” and a file path should always be a full absolute path like /etc/passwd instead of something like /tmp/../etc/././passwd.\n",
    "\n",
    "- The correct way of using assert is to help us debug while developing our code. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45293ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    assert isinstance(a, (int, float)), \"`a` must be a number\"\n",
    "    assert isinstance(b, (int, float)), \"`b` must be a number\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenitems(arr):\n",
    "    newarr = []\n",
    "    for i in range(len(arr)):\n",
    "        if i % 2 == 0:\n",
    "            newarr.append(arr[i])\n",
    "    assert len(newarr) * 2 >= len(arr)\n",
    "    return newarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307efffb",
   "metadata": {},
   "source": [
    "- While we develop this function, we are not sure our algorithm is correct. There are many things to check, but here we want to be sure that if we extracted every even-indexed item from the input, it should be at least half the length of the input array.\n",
    "\n",
    "- When we try to optimize the algorithm or polish the code, this condition must not be invalidated. We keep the assert statement at strategic locations to make sure we didn’t break our code after modifications. \n",
    "\n",
    "- Using assert this way is to check the steps inside a function.\n",
    "\n",
    "- If we write a complex algorithm, it is helpful to add assert to check for loop invariants, namely, the conditions that a loop should uphold. Consider the following code of binary search in a sorted array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(array, target):\n",
    "    \"\"\"Binary search on array for target\n",
    "\n",
    "    Args:\n",
    "        array: sorted array\n",
    "        target: the element to search for\n",
    "    Returns:\n",
    "        index n on the array such that array[n]==target\n",
    "        if the target not found, return -1\n",
    "    \"\"\"\n",
    "    s,e = 0, len(array)\n",
    "    while s < e:\n",
    "        m = (s+e)//2\n",
    "        if array[m] == target:\n",
    "            return m\n",
    "        elif array[m] > target:\n",
    "            e = m\n",
    "        elif array[m] < target:\n",
    "            s = m+1\n",
    "        assert m != (s+e)//2, \"we didn't move our midpoint\"\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2380f",
   "metadata": {},
   "source": [
    "- The last assert statement is to uphold our loop invariants. This is to make sure we didn’t make a mistake on the logic to update the start cursor s and end cursor e such that the midpoint m wouldn’t update in the next iteration.\n",
    "\n",
    "- If we replaced s = m+1 with s = m in the last elif branch and used the function on certain targets that do not exist in the array, the assert statement will warn us about this bug.\n",
    "\n",
    "## Guard Rails and Offensive Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363a617",
   "metadata": {},
   "source": [
    "- It is amazing to see Python comes with a NotImplementedError exception built-in. This is useful for what we call  offensive programming.\n",
    "\n",
    "- While the input sanitation is to help align the input to a format that our code expects, sometimes it is not easy to sanitize everything or is inconvenient for our future development.\n",
    "\n",
    "- One example is the following, in which we define a registering decorator and some functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90169373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "REGISTRY = {}\n",
    "\n",
    "def register(name):\n",
    "    def _decorator(fn):\n",
    "        REGISTRY[name] = fn\n",
    "        return fn\n",
    "    return _decorator\n",
    "\n",
    "@register(\"relu\")\n",
    "def rectified(x):\n",
    "    return x if x > 0 else 0\n",
    "\n",
    "@register(\"sigmoid\")\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def activate(x, funcname):\n",
    "    if funcname not in REGISTRY:\n",
    "        raise NotImplementedError(f\"Function {funcname} is not implemented\")\n",
    "    else:\n",
    "        func = REGISTRY[funcname]\n",
    "        return func(x)\n",
    "\n",
    "print(activate(1.23, \"relu\"))\n",
    "print(activate(1.23, \"sigmoid\"))\n",
    "print(activate(1.23, \"tanh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929663f5",
   "metadata": {},
   "source": [
    "- We raised NotImplementedError with a custom error message in our function activate().\n",
    "\n",
    "-  we can raise NotImplementedError in places where the condition is not entirely invalid, but it’s just that we are not ready to handle those cases yet.\n",
    "\n",
    "- This is useful when we gradually develop our program, which we implement one case at a time and address some corner cases later. \n",
    "\n",
    "- The principle here is that you should never let the anomaly proceed silently as your algorithm will not behave correctly and sometimes have dangerous effects\n",
    "\n",
    "## Good Practices to Avoid Bugs\n",
    "\n",
    "- First is the use of the functional paradigm. While we know Python has constructs that allow us to write an algorithm in functional syntax, the principle behind functional programming is to make no side effect on function calls.\n",
    "\n",
    "-  The “no side effect” principle is powerful in avoiding a lot of bugs since we can never mistakenly change something.\n",
    "\n",
    "-  we should be careful if the argument to our function is a mutable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ee205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a=[]):\n",
    "    a.append(1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d74c39",
   "metadata": {},
   "source": [
    "- It is trivial to see what this function does. However, when we call this function without any argument, the default is used and returned us [1]. When we call it again, a different default is used and returned us [1,1]. It is because the list [] we created at the function declaration as the default value for argument a is an initiated object. When we append a value to it, this object is mutated. The next time we call the function will see the mutated object.\n",
    "\n",
    "\n",
    "- And in case it is appropriate, we should make a copy of it. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ac973",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS = []\n",
    "\n",
    "def log(action):\n",
    "    LOGS.append(action)\n",
    "    \n",
    "data = {\"name\": None}\n",
    "for n in [\"Alice\", \"Bob\", \"Charlie\"]:\n",
    "    data[\"name\"] = n\n",
    "    ...  # do something with `data`\n",
    "    log(data)  # keep a record of what we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def log(action):\n",
    "    copied_action = copy.deepcopy(action)\n",
    "    LOGS.append(copied_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec18f2",
   "metadata": {},
   "source": [
    "- The other technique to avoid bugs is not to reinvent the wheel. In Python, we have a lot of nice containers and optimized operations. You should never try to create a stack data structure yourself since a list supports append() and pop(). \n",
    "\n",
    "- Similarly, if you need a queue, we have deque in the collections module from the standard library. \n",
    "\n",
    "- Python doesn’t come with a balanced search tree or linked list. But the dictionary is highly optimized, and we should consider using the dictionary whenever possible.\n",
    "\n",
    "- We have a JSON library, and we shouldn’t write our own. \n",
    "\n",
    "- If we need some numerical algorithms, check if you can get one from NumPy.\n",
    "\n",
    "- Another way to avoid bugs is to use better logic. An algorithm with a lot of loops and branches would be hard to follow and may even confuse ourselves. \n",
    "\n",
    "- It would be easier to spot errors if we could make our code clearer. For example, making a function that checks if the upper triangular part of a matrix contains any negative would be like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_in_upper_tri(matrix):\n",
    "    n_rows = len(matrix)\n",
    "    n_cols = len(matrix[0])\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            if i > j:\n",
    "                continue  # we are not in upper triangular\n",
    "            if matrix[i][j] < 0:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b7ee9",
   "metadata": {},
   "source": [
    "- But we also use a Python generator to break this into two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695bee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_tri(matrix):\n",
    "    n_rows = len(matrix)\n",
    "    n_cols = len(matrix[0])\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            if i > j:\n",
    "                continue  # we are not in upper triangular\n",
    "            yield matrix[i][j]\n",
    "\n",
    "def neg_in_upper_tri(matrix):\n",
    "    for element in get_upper_tri(matrix):\n",
    "        if element[i][j] < 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca59fa",
   "metadata": {},
   "source": [
    "-  If the function is more complicated, separating the nested loop into generators may help us make the code more maintainable.\n",
    "\n",
    "- Finally, consider adopting a coding style for your project. Having a consistent way to write code is the first step in offloading some of your mental burdens later when you read what you have written. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c59b1",
   "metadata": {},
   "source": [
    "## Multiprocessing in Python\n",
    "\n",
    "- Multiprocessing can make a program substantially more efficient by running multiple tasks in parallel instead of sequentially. A similar term is multithreading, but they are different.\n",
    "\n",
    "- A process is a program loaded into memory to run and does not share its memory with other processes. A thread is an execution unit within a process. Multiple threads run in a process and share the process’s memory space with each other.\n",
    "\n",
    "- Python’s Global Interpreter Lock (GIL) only allows one thread to be run at a time under the interpreter, which means you can’t enjoy the performance benefit of multithreading if the Python interpreter is required. This is what gives multiprocessing an upper hand over threading in Python. \n",
    "\n",
    "- Multiple processes can be run in parallel because each process has its own interpreter that executes the instructions allocated to it. \n",
    "\n",
    "- Also, the OS would see your program in multiple processes and schedule them separately, i.e., your program gets a larger share of computer resources in total. So, multiprocessing is faster when the program is CPU-bound. \n",
    "\n",
    "### Basic multiprocessing \n",
    "\n",
    "- Let’s look at this function, task(), that sleeps for 0.5 seconds and prints before and after the sleep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b45c678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def task():\n",
    "    print('Sleeping for 0.5 seconds')\n",
    "    time.sleep(0.5)\n",
    "    print('Finished sleeping')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb4115",
   "metadata": {},
   "source": [
    "- To create a process, we simply say so using the multiprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d00199e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "p1 = multiprocessing.Process(target=task)\n",
    "p2 = multiprocessing.Process(target=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450e63e",
   "metadata": {},
   "source": [
    "- The target argument to the Process() specifies the target function that the process runs. But these processes do not run immediately until we start them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bc4f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca934a53",
   "metadata": {},
   "source": [
    "- A complete concurrent program would be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd50353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def task():\n",
    "    print('Sleeping for 0.5 seconds')\n",
    "    time.sleep(0.5)\n",
    "    print('Finished sleeping')\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    start_time = time.perf_counter()\n",
    "    processes = []\n",
    "\n",
    "    # Creates 10 processes then starts them\n",
    "    for i in range(10):\n",
    "        p = multiprocessing.Process(target = task)\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    # Joins all the processes \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    finish_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Program finished in {finish_time-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a7fe5",
   "metadata": {},
   "source": [
    "- We must fence our main program under if __name__ == \"__main__\" or otherwise the multiprocessing module will complain. This safety construct guarantees Python finishes analyzing the program before the sub-process is created.\n",
    "\n",
    "- We need to call the join() function on the two processes to make them run before the time prints.\n",
    "\n",
    "- This is because three processes are going on: p1, p2, and the main process. The main process is the one that keeps track of the time and prints the time taken to execute. \n",
    "\n",
    "- The join() function allows us to make other processes wait until the processes that had join() called on it are complete.\n",
    "\n",
    "- We should make the line of finish_time run no earlier than the processes p1 and p2 are finished.\n",
    "\n",
    "### Multiprocessing for Real Use\n",
    "\n",
    "- Starting a new process and then joining it back to the main process is how multiprocessing works in Python (as in many other languages).\n",
    "\n",
    "- The reason we want to run multiprocessing is probably to execute many different tasks concurrently for speed\n",
    "\n",
    "- Let’s consider a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa375d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b745c",
   "metadata": {},
   "source": [
    "- If we want to run it with arguments 1 to 1,000, we can create 1,000 processes and run them in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f94b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # this does not work\n",
    "    processes = [multiprocessing.Process(target=cube, args=(x,)) for x in range(1,1000)]\n",
    "    [p.start() for p in processes]\n",
    "    result = [p.join() for p in processes]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53cb3c",
   "metadata": {},
   "source": [
    "- However, this will not work as you probably have only a handful of cores in your computer. Running 1,000 processes is creating too much overhead and overwhelming the capacity of your OS. Also, you may have exhausted your memory. \n",
    "\n",
    "- The better way is to run a process pool to limit the number of processes that can be run at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(3)\n",
    "    start_time = time.perf_counter()\n",
    "    processes = [pool.apply_async(cube, args=(x,)) for x in range(1,1000)]\n",
    "    result = [p.get() for p in processes]\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"Program finished in {finish_time-start_time} seconds\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda1b93",
   "metadata": {},
   "source": [
    "- The argument for multiprocessing.Pool() is the number of processes to create in the pool. If omitted, Python will make it equal to the number of cores you have in your computer.\n",
    "\n",
    "- We use the apply_async() function to pass the arguments to the function cube in a list comprehension. This will create tasks for the pool to run. \n",
    "\n",
    "- It is called “async” (asynchronous) because we didn’t wait for the task to finish, and the main process may continue to run. Therefore the apply_async() function does not return the result but an object that we can use, get(), to wait for the task to finish and retrieve the result. \n",
    "\n",
    "- Since we get the result in a list comprehension, the order of the result corresponds to the arguments we created in the asynchronous tasks. However, this does not mean the processes are started or finished in this order inside the pool.\n",
    "\n",
    "- If you think writing lines of code to start processes and join them is too explicit, you can consider using map() instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50085d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(3)\n",
    "    start_time = time.perf_counter()\n",
    "    result = pool.map(cube, range(1,1000))\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"Program finished in {finish_time-start_time} seconds\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a8a80",
   "metadata": {},
   "source": [
    "- We don’t have the start and join here because it is hidden behind the pool.map() function. What it does is split the iterable range(1,1000) into chunks and runs each chunk in the pool. The map function is a parallel version of the list comprehension\n",
    "\n",
    "- But the modern-day alternative is to use map from concurrent.futures, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with concurrent.futures.ProcessPoolExecutor(3) as executor:\n",
    "        start_time = time.perf_counter()\n",
    "        result = list(executor.map(cube, range(1,1000)))\n",
    "        finish_time = time.perf_counter()\n",
    "    print(f\"Program finished in {finish_time-start_time} seconds\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a5982",
   "metadata": {},
   "source": [
    "- This code is running the multiprocessing module under the hood. The beauty of doing so is that we can change the program from multiprocessing to multithreading by simply replacing ProcessPoolExecutor with ThreadPoolExecutor.\n",
    "\n",
    "- Of course, you have to consider whether the global interpreter lock is an issue for your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f99ca",
   "metadata": {},
   "source": [
    "### Using joblib\n",
    "\n",
    "- The package joblib is a set of tools to make parallel computing easier. It is a common third-party library for multiprocessing. \n",
    "\n",
    "- It also provides caching and serialization functions. \n",
    "\n",
    "- We can convert our previous example into the following to use joblib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "result = Parallel(n_jobs=3)(delayed(cube)(i) for i in range(1,1000))\n",
    "finish_time = time.perf_counter()\n",
    "print(f\"Program finished in {finish_time-start_time} seconds\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee601624",
   "metadata": {},
   "source": [
    "- Indeed, it is intuitive to see what it does. The delayed() function is a wrapper to another function to make a “delayed” version of the function call. Which means it will not execute the function immediately when it is called.\n",
    "\n",
    "- Then we call the delayed function multiple times with different sets of arguments we want to pass to it. For example, when we give integer 1 to the delayed version of the function cube, instead of computing the result, we produce a tuple, (cube, (1,), {}) for the function object, the positional arguments, and keyword arguments, respectively.\n",
    "\n",
    "- We created the engine instance with Parallel(). When it is invoked like a function with the list of tuples as an argument, it will actually execute the job as specified by each tuple in parallel and collect the result as a list after all jobs are finished. Here we created the Parallel() instance with n_jobs=3, so there will be three processes running in parallel.\n",
    "\n",
    "- We can also write the tuples directly. Hence the code above can be rewritten as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Parallel(n_jobs=3)((cube, (i,), {}) for i in range(1,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c048da",
   "metadata": {},
   "source": [
    "- The benefit of using joblib is that we can run the code in multithread by simply adding an additional argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Parallel(n_jobs=3, prefer=\"threads\")(delayed(cube)(i) for i in range(1,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc05075",
   "metadata": {},
   "source": [
    "- And this hides all the details of running functions in parallel. We simply use a syntax not too much different from a plain list comprehension."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
